{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load libraries and define db_connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "query dml.create_function_public_ghh_decode_id_to_hash at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:1 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.drop_function_public_ghh_decode_id_to_hash at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:35 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.create_function_public_ghh_decode_hash_to_wkt at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:41 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.drop_function_public_ghh_decode_hash_to_wkt at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:60 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.create_function_public_ghh_decode_id_to_wkt at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:66 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.drop_function_public_ghh_decode_id_to_wkt at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:92 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.create_function_public_ghh_encode_xy_to_id at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:98 may not be a select, consider adding an operator, eg '!'\n",
      "query dml.drop_function_public_ghh_encode_xy_to_id at /home/matthiasdaues/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/sql/dml/ghh_functions.sql:117 may not be a select, consider adding an operator, eg '!'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import aiosql\n",
    "import multiprocessing as mp\n",
    "from dotenv import load_dotenv\n",
    "from operator import itemgetter\n",
    "\n",
    "from pgnetworks_processing.python.utilities import Config, create_run_id\n",
    "from pgnetworks_processing.python import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742321281\n"
     ]
    }
   ],
   "source": [
    "# set run_id and initiate workstep_idx\n",
    "\n",
    "run_id = create_run_id()\n",
    "workstep_idx = 0\n",
    "\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tear down and set stuff up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tear stuff down and set it up fresh\n",
    "\n",
    "with psycopg2.connect(Config.connect_db) as conn:\n",
    "    try:\n",
    "#       # drop tables and types\n",
    "        Config.queries.ddl.drop_table_edges(conn)\n",
    "        Config.queries.ddl.drop_table_vertex_2_edge(conn)\n",
    "        Config.queries.ddl.drop_table_junctioned_edges(conn)\n",
    "        Config.queries.ddl.drop_table_segments(conn)\n",
    "        Config.queries.ddl.drop_type_segment_processing(conn)\n",
    "        Config.queries.ddl.drop_table_nodes(conn)\n",
    "        Config.queries.ddl.drop_table_selector_grid(conn)\n",
    "#       # Config.queries.ddl.drop_table_log(conn)\n",
    "\n",
    "#       # drop procedures or functions\n",
    "        Config.queries.dml.drop_procedure_copy_segments_to_edges(conn)\n",
    "        Config.queries.dml.drop_procedure_join_vertex_2_edge(conn)\n",
    "        Config.queries.dml.drop_procedure_process_junctions_and_edges(conn)\n",
    "        Config.queries.dml.drop_procedure_calculate_selector_grid(conn)\n",
    "        Config.queries.dml.drop_procedure_segmentize_road_network(conn)\n",
    "        Config.queries.dml.drop_procedure_count_node_degree(conn)\n",
    "        \n",
    "#       # rebuild tables and types\n",
    "        Config.queries.ddl.create_table_edges(conn)\n",
    "        Config.queries.ddl.create_table_vertex_2_edge(conn)\n",
    "        Config.queries.ddl.create_table_junctioned_edges(conn)\n",
    "        Config.queries.ddl.create_type_segment_processing(conn)\n",
    "        Config.queries.ddl.create_table_segments(conn)\n",
    "        Config.queries.ddl.create_table_nodes(conn)\n",
    "        Config.queries.ddl.create_table_selector_grid(conn)\n",
    "#       # Config.queries.ddl.create_table_log(conn)\n",
    "        \n",
    "#       # create and replace assets\n",
    "        Config.queries.dml.create_procedure_copy_segments_to_edges(conn)\n",
    "        Config.queries.dml.create_procedure_join_vertex_2_edge(conn)\n",
    "        Config.queries.dml.create_procedure_process_junctions_and_edges(conn)\n",
    "        Config.queries.dml.create_procedure_calculate_selector_grid(conn)\n",
    "        Config.queries.dml.create_procedure_segmentize_road_network(conn)\n",
    "        Config.queries.dml.create_procedure_count_node_degree(conn)\n",
    "        \n",
    "        conn.commit()\n",
    "    \n",
    "    except psycopg2.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download sources and copy data to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess data in the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *perform processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lower and upper bounds for the \"join_vertex_2_edge\" procedure\n",
    "\n",
    "from pgnetworks_processing.python import functions\n",
    "\n",
    "chunk_bound_query_name = 'find_bounds_in_poi_table'\n",
    "workstep_query_name = 'join_vertex_2_edge'\n",
    "chunk_size = 200000\n",
    "workstep_idx += 1\n",
    "params_list = functions.create_range_bound_params_list(chunk_bound_query_name, workstep_query_name, chunk_size, workstep_idx, run_id)\n",
    "# params_list = params_list[:1]\n",
    "# params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# join the vertices to the closest edge\u001b[39;00m\n\u001b[1;32m      3\u001b[0m workstep_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiprocess_id_range_workstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkstep_query_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkstep_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/datenschoenheit/pgNetworks/pgnetworks_processing/pgnetworks_processing/python/functions/multiprocess_id_range_workstep.py:54\u001b[0m, in \u001b[0;36mmultiprocess_id_range_workstep\u001b[0;34m(params_list, workstep_query_name, workstep_idx, run_id)\u001b[0m\n\u001b[1;32m     51\u001b[0m start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow(timezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39misoformat()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mCONCURRENCY) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_range_workstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# get end_date\u001b[39;00m\n\u001b[1;32m     57\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow(timezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39misoformat()\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# join the vertices to the closest edge\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.multiprocess_id_range_workstep(params_list, workstep_query_name, workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the table vertex_2_edge for the next bound search run\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_vertex_2_edge_edge_id_idx', workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bounds for the \"process junctions and edges\" procedure\n",
    "\n",
    "from pgnetworks_processing.python import functions\n",
    "\n",
    "chunk_bound_query_name = 'find_bounds_in_vertex_2_edge'\n",
    "workstep_query_name = 'process_junctions_and_edges'\n",
    "chunk_size = 20000\n",
    "workstep_idx += 1\n",
    "params_list = functions.create_range_bound_params_list(chunk_bound_query_name, workstep_query_name, chunk_size, workstep_idx, run_id)\n",
    "# params_list = params_list[:1]\n",
    "# params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the junctions and edges (segmentize the near_net edges)\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.multiprocess_id_range_workstep(params_list, workstep_query_name, workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the table segments for the next bound search run\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_segments_edge_id_idx', workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the selector grid\n",
    "\n",
    "# workstep_idx += 1\n",
    "# params_list = functions.calculate_selector_grid(workstep_idx, run_id)\n",
    "# params_list = params_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the parameter list for the spatially bounded workstep\n",
    "\n",
    "spatial_bound_query_name = 'select_selector_grid'\n",
    "spatial_workstep_query_name = 'segmentize_road_network'\n",
    "workstep_idx += 1\n",
    "params_list = functions.create_spatial_workstep_params_list(spatial_bound_query_name, spatial_workstep_query_name, workstep_idx, run_id)\n",
    "# params_list = params_list[:1]\n",
    "# print(len(params_list))\n",
    "# params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the remaining road network edges (process the far_net edges)\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.multiprocess_spatial_workstep(params_list, spatial_workstep_query_name, workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the segments table\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_segments_geom_idx', workstep_idx, run_id)\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_segments_node_1_idx', workstep_idx, run_id)\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_segments_node_2_idx', workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bounds for the \"copy segments to edges\" procedure\n",
    "\n",
    "from pgnetworks_processing.python import functions\n",
    "\n",
    "chunk_bound_query_name = 'find_bounds_in_segments'\n",
    "workstep_query_name = 'copy_segments_to_edges'\n",
    "chunk_size = 5000000\n",
    "workstep_idx += 1\n",
    "params_list = functions.create_range_bound_params_list(chunk_bound_query_name, workstep_query_name, chunk_size, workstep_idx, run_id)\n",
    "# params_list = params_list[:1]\n",
    "# params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy segments to edges\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.singleprocess_id_range_workstep(params_list, workstep_query_name, workstep_idx, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the edges table\n",
    "\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_edges_geom_idx', workstep_idx, run_id)\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_edges_node_1_id_idx', workstep_idx, run_id)\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_edges_node_2_id_idx', workstep_idx, run_id)\n",
    "workstep_idx += 1\n",
    "functions.create_index('create_index_source_edge_id_idx', workstep_idx, run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
